{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making a Summary of a Text**\n",
    "\n",
    "\n",
    "POS stands for **part of speech**. \n",
    "<br>\n",
    "TextBlob will  tell us what part of speech each word in a text corresponds to. It can tell us if a word in a sentence is functioning as a noun, an adjective, a verb, etc. for that, we will need to install the following nltk component:\n",
    "\n",
    "* `import nltk`\n",
    "* `nltk.download('averaged_perceptron_tagger')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computers NNS\n",
      "are VBP\n",
      "heavy JJ\n",
      "Programmers NNS\n",
      "work VBP\n",
      "hard RB\n",
      "The DT\n",
      "sun NN\n",
      "shines NNS\n"
     ]
    }
   ],
   "source": [
    "# define the text to tagg\n",
    "txt = TextBlob(' Computers are heavy. Programmers work hard. The sun shines')\n",
    "# extract the tagging using the method \".tags\"\n",
    "for word,pos in txt.tags:\n",
    "    print(word,pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case Study: Making a summary of a text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the text to summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'US stocks rose after President Donald Trump announced tariffs \\\n",
    "that were narrower than some traders had anticipated. Treasuries and the\\\n",
    "dollar gained. The S&P 500 advanced for the fourth time in five days as \\\n",
    "investors found relief in the president’s decision to exclude Canada and Mexico\\\n",
    "while giving other countries wiggle room from levies on imports of steel and \\\n",
    "aluminum that will take effect in 15 days. Technology companies paced gains. \\\n",
    "Ten-year Treasury yields fell to 2.86 percent. \\\n",
    "The dollar rose against the euro after the European Central Bank’s decided to drop \\\n",
    "a pledge to increase asset purchases if necessary, and as President Mario Draghi \\\n",
    "downplayed the change. Crude oil traded near $60 a barrel and gold slipped as a \\\n",
    "Bloomberg gauge of commodities slid for a second day.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Method A: Finding some random words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are in total 133 words in the text\n",
      "\n",
      "This text is about...\n",
      "asset\n",
      "steel\n",
      "thedollar\n",
      "pledge\n",
      "oil\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "\n",
    "# gather words\n",
    "nouns = list()\n",
    "for word, tag in blob.tags:\n",
    "    if tag == 'NN':\n",
    "        nouns.append(word.lemmatize())\n",
    "\n",
    "print('There are in total',len(blob.tags),'words in the text\\n')\n",
    "\n",
    "#pick 5 names from the list\n",
    "\n",
    "print('This text is about...')\n",
    "for i in np.random.choice(np.arange(0,len(nouns)),5,replace=False):\n",
    "    word = Word(nouns[i])\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method B : Finding the shortes sentences<br>\n",
    "Make a list of sentences that contain no more than 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_sentences = list()\n",
    "for sentence in blob.sentences:\n",
    "    if len(sentence.words) <= 5:\n",
    "        short_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Treasuries and thedollar gained.\"),\n",
       " Sentence(\"Technology companies paced gains.\")]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in short_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method C: Retrieve the nouns from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us stocks\n",
      "donald trump\n",
      "treasuries\n",
      "president ’ s decision\n",
      "canada\n",
      "mexicowhile\n",
      "countries wiggle room\n",
      "technology companies\n",
      "ten-year\n",
      "treasury yields\n",
      "european central bank ’ s\n",
      "mario draghi\n",
      "crude\n",
      "bloomberg\n"
     ]
    }
   ],
   "source": [
    "noun_phrases = blob.noun_phrases\n",
    "\n",
    "for i in noun_phrases:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
