{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2\n",
    "## Introduction to Sklearn\n",
    "### Pipelines!\n",
    "\n",
    "<ol>\n",
    "<li> Used data: Boston Data Set ( https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html )\n",
    "<li> Notebook Goal: Learn how to build a pipeline in sklearn. Use pipelines for hyperparameter tuning and model selection\n",
    "<li> Extra Exercise: Yes, see below.\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Boston Housing data set. \n",
    "\n",
    "This data set consists of 14 numerical features. The goal of this notebook is to construct a regression model that tries to predict the median house price of a house in Boston using several explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df = pd.read_csv('../Data//housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following plan of attack:\n",
    "<ol>\n",
    "<li> Split the data set in a training and a test data set\n",
    "<li> Standardize the training data using StandardScaler\n",
    "<li> Then, reduce the dimension of the model using PCA\n",
    "<li> Afterwards, perform Ridge regression on the principal components\n",
    "<li> Evaluate the model performance on the test set using the R-squared.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first do this without using a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345884564889062"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['MEDV'],axis=1), df['MEDV'], random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "ridge=Ridge()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test = pca.transform(X_test)\n",
    "preds = ridge.predict(X_test)\n",
    "\n",
    "r2_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The messy part of this code is that we have some repetition: first apply either fit_transform or fit three times, then use transform or predict three times. \n",
    "\n",
    "Pipelines essentially just group the desired models and runs them sequentially. A pipeline consists of an array of several steps, each step has as format ('Name_of_step','method used in step') where 'method_used_in_step' is a class from Sklearn (or your own custom class). \n",
    "\n",
    "The resulting pipeline is then a typical sklearn class, with fit and predict methods. Calling a fit on training data then sequentially fits (and transforms) the methods in the pipeline to the training data. Using the predict function then applies these fitted transformers to the test data and returns the predictions. \n",
    "\n",
    "Because everything is done at once, the probability of data leakage is very low!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6357103588722749"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()), #Step one: Scaling the data\n",
    "        ('reduce_dim', PCA()), #Step two: perform PCA in order to reduce dimensions\n",
    "        ('regressor', Ridge()) #Step three: Bring in the regression model\n",
    "\n",
    "    ]\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Finetuning\n",
    "\n",
    "In this section, we will consider how to fine-tune the hyperparameters of the model. Recall that hyperparameters are model-specific parameters which are __user-supplied__ and are __NOT__ part of the fitting procedure. Examples are the amount of neighbours in the k-NN algorithm, or the learning rate in some neural networks.\n",
    "\n",
    "For some hyperparameters there are specific rules that one can follow, for example the scree plot in PCA. \n",
    "A more general rule is just to use the hyperparameters which leads to the best fitting model! \n",
    "\n",
    "This is basically what we will do in the next section. We will supply for each hyperparameter an interval of possible values. We will then use a method called GridSearchCV which considers each hyperparameter combination, fits this to the data and evaluates the performance of this model. In order to reduce the risk of overfitting, this method uses cross validation.\n",
    "\n",
    "The GridSearchCV method takes as input the pipeline (without hyperparameters) and the chosen intervals. It returns the best performing model, fit on the data.\n",
    "\n",
    "As an example, we will consider the previous setting. We think that the number of components for PCA is between 1 and 10, and that the best fitting regularization parameter alpha (see documentation!) lies in the set \n",
    "$$\n",
    "\\alpha \\in \\left\\{ 2^{-6}, 2^{-5}, ..., 2^{4}, 2^5 \\right\\}.\n",
    "$$\n",
    "\n",
    "Recall that the naming convention of the pipeline consisted of a pair ('Name_of_step', 'Method_of_step'). If we want to change a hyperparameter called 'theta' for the method in this step using GridSearchCV, we will use the following naming convention\n",
    "<ol>\n",
    "<li> Name of the step in the pipe : 'Name_of_step'\n",
    "<li> Double underscore\n",
    "<li> Name of the hyperparameter: 'theta'\n",
    "</ol>\n",
    "In our case: Name_of_step__theta.\n",
    "\n",
    "Following code should make this clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_features = np.arange(1,11)\n",
    "alpha_to_test = 2.0**np.arange(-6,6)\n",
    "\n",
    "params_to_consider = {'reduce_dim__n_components': number_features, \n",
    "                    'regressor__alpha': alpha_to_test   \n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then continue as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Final score is:  0.57801002901813\n"
     ]
    }
   ],
   "source": [
    "gridsearch = GridSearchCV(pipe, param_grid = params_to_consider, verbose=1).fit(X_train,y_train)\n",
    "print('Final score is: ', gridsearch.score(X_test,y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we had 120 candidates. This comes from the fact that we have 10 different values of N_components and 12 different values of alpha.\n",
    "\n",
    "When fitting your pipeline, make sure not to include impossible values! Not only is this bad practice, it can blow up the amount of necessary searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "We can easily extend above framework so that it can also compare different model classes, instead of only models of the same class but with different hyperparameters. \n",
    "\n",
    "Suppose for example we are not sure which choice would be the best: Standardization or Robust scaling. We can tweak the code above to find the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Testing score: 0.6364746260666787\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', []),\n",
    "    ('reduce_dim',PCA()),\n",
    "    ('regressor',Ridge())\n",
    "])\n",
    "\n",
    "grid = {'scaler':[StandardScaler(),RobustScaler()]}\n",
    "\n",
    "gridsearch = GridSearchCV(pipe,grid,verbose=1).fit(X_train,y_train)\n",
    "print('Testing score:', gridsearch.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': RobustScaler()}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_params_ #Robust scaler was the best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__:\n",
    "\n",
    "Extend the above generalization so that it can consider not only different scalers, but also different regression methods. Compare in this way Ridge regression with OLS regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
